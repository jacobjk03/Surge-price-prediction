{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models from Scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Model evaluations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training data\n",
    "df = pd.read_csv(\"sigma_cabs.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131662 entries, 0 to 131661\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Trip_ID                      131662 non-null  object \n",
      " 1   Trip_Distance                131662 non-null  float64\n",
      " 2   Type_of_Cab                  111452 non-null  object \n",
      " 3   Customer_Since_Months        125742 non-null  float64\n",
      " 4   Life_Style_Index             111469 non-null  float64\n",
      " 5   Confidence_Life_Style_Index  111469 non-null  object \n",
      " 6   Destination_Type             131662 non-null  object \n",
      " 7   Customer_Rating              131662 non-null  float64\n",
      " 8   Cancellation_Last_1Month     131662 non-null  int64  \n",
      " 9   Var1                         60632 non-null   float64\n",
      " 10  Var2                         131662 non-null  int64  \n",
      " 11  Var3                         131662 non-null  int64  \n",
      " 12  Gender                       131662 non-null  object \n",
      " 13  Surge_Pricing_Type           131662 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(5)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_ID                            0\n",
       "Trip_Distance                      0\n",
       "Type_of_Cab                    20210\n",
       "Customer_Since_Months           5920\n",
       "Life_Style_Index               20193\n",
       "Confidence_Life_Style_Index    20193\n",
       "Destination_Type                   0\n",
       "Customer_Rating                    0\n",
       "Cancellation_Last_1Month           0\n",
       "Var1                           71030\n",
       "Var2                               0\n",
       "Var3                               0\n",
       "Gender                             0\n",
       "Surge_Pricing_Type                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_ID\n",
      "Type_of_Cab\n",
      "Confidence_Life_Style_Index\n",
      "Destination_Type\n",
      "Gender\n"
     ]
    }
   ],
   "source": [
    "# Find the columns which contains string\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will change all the string columns to categorical values\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131662 entries, 0 to 131661\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count   Dtype   \n",
      "---  ------                       --------------   -----   \n",
      " 0   Trip_ID                      131662 non-null  category\n",
      " 1   Trip_Distance                131662 non-null  float64 \n",
      " 2   Type_of_Cab                  111452 non-null  category\n",
      " 3   Customer_Since_Months        125742 non-null  float64 \n",
      " 4   Life_Style_Index             111469 non-null  float64 \n",
      " 5   Confidence_Life_Style_Index  111469 non-null  category\n",
      " 6   Destination_Type             131662 non-null  category\n",
      " 7   Customer_Rating              131662 non-null  float64 \n",
      " 8   Cancellation_Last_1Month     131662 non-null  int64   \n",
      " 9   Var1                         60632 non-null   float64 \n",
      " 10  Var2                         131662 non-null  int64   \n",
      " 11  Var3                         131662 non-null  int64   \n",
      " 12  Gender                       131662 non-null  category\n",
      " 13  Surge_Pricing_Type           131662 non-null  int64   \n",
      "dtypes: category(5), float64(5), int64(4)\n",
      "memory usage: 15.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_ID                         0.000000\n",
       "Trip_Distance                   0.000000\n",
       "Type_of_Cab                    15.349911\n",
       "Customer_Since_Months           4.496362\n",
       "Life_Style_Index               15.336999\n",
       "Confidence_Life_Style_Index    15.336999\n",
       "Destination_Type                0.000000\n",
       "Customer_Rating                 0.000000\n",
       "Cancellation_Last_1Month        0.000000\n",
       "Var1                           53.948748\n",
       "Var2                            0.000000\n",
       "Var3                            0.000000\n",
       "Gender                          0.000000\n",
       "Surge_Pricing_Type              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isnull().sum()/len(df))*100 # To see in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export current temp dataframe\n",
    "df.to_csv(\"train_tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data\n",
    "df = pd.read_csv(\"train_tmp.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_ID</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T0005689460</td>\n",
       "      <td>6.77</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.42769</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>3.90500</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T0005689461</td>\n",
       "      <td>29.47</td>\n",
       "      <td>B</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.78245</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T0005689464</td>\n",
       "      <td>41.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>3.50125</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T0005689465</td>\n",
       "      <td>61.56</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>3.45375</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T0005689467</td>\n",
       "      <td>54.95</td>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.03453</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>3.40250</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49</td>\n",
       "      <td>102</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trip_ID  Trip_Distance Type_of_Cab  Customer_Since_Months  \\\n",
       "0  T0005689460           6.77           B                    1.0   \n",
       "1  T0005689461          29.47           B                   10.0   \n",
       "2  T0005689464          41.58         NaN                   10.0   \n",
       "3  T0005689465          61.56           C                   10.0   \n",
       "4  T0005689467          54.95           C                   10.0   \n",
       "\n",
       "   Life_Style_Index Confidence_Life_Style_Index Destination_Type  \\\n",
       "0           2.42769                           A                A   \n",
       "1           2.78245                           B                A   \n",
       "2               NaN                         NaN                E   \n",
       "3               NaN                         NaN                A   \n",
       "4           3.03453                           B                A   \n",
       "\n",
       "   Customer_Rating  Cancellation_Last_1Month  Var1  Var2  Var3  Gender  \\\n",
       "0          3.90500                         0  40.0    46    60  Female   \n",
       "1          3.45000                         0  38.0    56    78    Male   \n",
       "2          3.50125                         2   NaN    56    77    Male   \n",
       "3          3.45375                         0   NaN    52    74    Male   \n",
       "4          3.40250                         4  51.0    49   102    Male   \n",
       "\n",
       "   Surge_Pricing_Type  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   2  \n",
       "3                   3  \n",
       "4                   2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_ID                            0\n",
       "Trip_Distance                      0\n",
       "Type_of_Cab                    20210\n",
       "Customer_Since_Months           5920\n",
       "Life_Style_Index               20193\n",
       "Confidence_Life_Style_Index    20193\n",
       "Destination_Type                   0\n",
       "Customer_Rating                    0\n",
       "Cancellation_Last_1Month           0\n",
       "Var1                           71030\n",
       "Var2                               0\n",
       "Var3                               0\n",
       "Gender                             0\n",
       "Surge_Pricing_Type                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values\n",
    "\n",
    "### Fill numeric missing value first (Original numeric values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_Distance\n",
      "Customer_Since_Months\n",
      "Life_Style_Index\n",
      "Customer_Rating\n",
      "Cancellation_Last_1Month\n",
      "Var1\n",
      "Var2\n",
      "Var3\n",
      "Surge_Pricing_Type\n"
     ]
    }
   ],
   "source": [
    "for label, content in df.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_Since_Months\n",
      "Life_Style_Index\n",
      "Var1\n"
     ]
    }
   ],
   "source": [
    "# Check for which numeric values there is NULL values\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_numeric_dtype(content)&(pd.isna(content).sum()!=0):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets fill both of these columns with median values\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_numeric_dtype(content)&(pd.isna(content).sum()!=0):\n",
    "        # Add a binary column for that feature having null values (If the data was missing)\n",
    "        df[label+\"_is_missing\"] = pd.isnull(content) # For future it will only show if the column was missing or not by TRUE or False\n",
    "        #will give TRUE if NULL\n",
    "        # Fill missing numeric value with median\n",
    "        df[label] = content.fillna(content.median()) #median is mnore robust than the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 999100.8991008991, 100.0, 100.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrating how median is more robust than mean\n",
    "hundreds = np.full((1000),100)\n",
    "hundreds_billion = np.append(hundreds, 1000000000)\n",
    "\n",
    "np.mean(hundreds), np.mean(hundreds_billion),   np.median(hundreds), np.median(hundreds_billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if now is there any NULL numeric value\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_numeric_dtype(content)&(pd.isna(content).sum()!=0):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    42680\n",
       "6.0     13295\n",
       "2.0     11621\n",
       "3.0     10351\n",
       "0.0     10169\n",
       "5.0      8641\n",
       "1.0      8297\n",
       "4.0      7726\n",
       "7.0      7407\n",
       "8.0      6328\n",
       "9.0      5147\n",
       "Name: Customer_Since_Months, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check how many examples were missing\n",
    "df.Customer_Since_Months.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_ID                                 0\n",
       "Trip_Distance                           0\n",
       "Type_of_Cab                         20210\n",
       "Customer_Since_Months                   0\n",
       "Life_Style_Index                        0\n",
       "Confidence_Life_Style_Index         20193\n",
       "Destination_Type                        0\n",
       "Customer_Rating                         0\n",
       "Cancellation_Last_1Month                0\n",
       "Var1                                    0\n",
       "Var2                                    0\n",
       "Var3                                    0\n",
       "Gender                                  0\n",
       "Surge_Pricing_Type                      0\n",
       "Customer_Since_Months_is_missing        0\n",
       "Life_Style_Index_is_missing             0\n",
       "Var1_is_missing                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_ID\n",
      "Type_of_Cab\n",
      "Confidence_Life_Style_Index\n",
      "Destination_Type\n",
      "Gender\n"
     ]
    }
   ],
   "source": [
    "# Now lets fill the rest of the missing values (ie categorical we converted)\n",
    "# so now lets find columns that are not numeric data (Categorical)\n",
    "for label, content in df.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into numbers and fill missing\n",
    "for label, content in df.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        # Add binary column to indicate whether sample had missing value\n",
    "        df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        # Turn categories into numbers and add +1\n",
    "        # Adding 1 as when there was a missing value its code is -1 so to make it 0 shown in abov cell\n",
    "        df[label] = pd.Categorical(content).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trip_ID                                   0\n",
       "Trip_Distance                             0\n",
       "Type_of_Cab                               0\n",
       "Customer_Since_Months                     0\n",
       "Life_Style_Index                          0\n",
       "Confidence_Life_Style_Index               0\n",
       "Destination_Type                          0\n",
       "Customer_Rating                           0\n",
       "Cancellation_Last_1Month                  0\n",
       "Var1                                      0\n",
       "Var2                                      0\n",
       "Var3                                      0\n",
       "Gender                                    0\n",
       "Surge_Pricing_Type                        0\n",
       "Customer_Since_Months_is_missing          0\n",
       "Life_Style_Index_is_missing               0\n",
       "Var1_is_missing                           0\n",
       "Trip_ID_is_missing                        0\n",
       "Type_of_Cab_is_missing                    0\n",
       "Confidence_Life_Style_Index_is_missing    0\n",
       "Destination_Type_is_missing               0\n",
       "Gender_is_missing                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Train and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Surge_Pricing_Type\", axis=1)\n",
    "y = df[\"Surge_Pricing_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So there is no missing values as well as all our data is NUMERIC now we can build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time    \n",
    "# Put Models in a dictionary\n",
    "models = {\"SGDRegressor\": SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "          \"Support Vector Machine\": SVR(),\n",
    "          \"Random Forest\": RandomForestRegressor()}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models.\n",
    "    models : a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data (no labels)\n",
    "    X_test : testing data (no labels)\n",
    "    y_train : training labels\n",
    "    y_test : test labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set Random seed\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Make a dictionary to keep the model score\n",
    "    model_score = {}\n",
    "    \n",
    "    # Loop through the models\n",
    "    for name,model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate the model and apend its score to the model_score\n",
    "        model_score[name] = model.score(X_test, y_test)\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SGDRegressor': -5.930150392923666e+33,\n",
       " 'Support Vector Machine': -0.005079598633456195,\n",
       " 'Random Forest': 0.3986540210782651}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = fit_and_score(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As Random Forrest model has the highest R2 value we will use it for hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (It uses RMSLE)\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n",
    "\n",
    "# We need root mean squared log error (RMSLE) so make a function\n",
    "def rmsle(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    Calculate Root mean squared log error between predictions and tru labels.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
    "\n",
    "# Calculate function to evaluate model on different levels\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "              \"Test MAE\": mean_absolute_error(y_test, test_preds),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "              \"Test RMSLE\": rmsle(y_test, test_preds),\n",
    "              \"Training R^2\": r2_score(y_train, train_preds),   # or use model.score()\n",
    "              \"Test R^2\": r2_score(y_test, test_preds),\n",
    "              \"ACCURACY on training data\": model.score(X_train, y_train)}\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training MAE': 0.1621035991987012,\n",
       " 'Test MAE': 0.4407207686173243,\n",
       " 'Training RMSLE': 0.07737441022266309,\n",
       " 'Test RMSLE': 0.1970501253714191,\n",
       " 'Training R^2': 0.9153118376660967,\n",
       " 'Test R^2': 0.399021936587889,\n",
       " 'ACCURACY on training data': 0.9153118376660967}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our model have good trainning R2 value but low test R2 value so its a case of overfitting we will try to do hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tunning with RandomizedSearchCV\n",
    "\n",
    "we're going to tune:\n",
    "* Random Forest classifier model() \n",
    "\n",
    "using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got hyperparameter grids setup for each of our model. let's tune them using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestRegressor(), n_iter=5,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for logistic regression\n",
    "rs_rf = RandomizedSearchCV(RandomForestRegressor(),\n",
    "                            param_distributions=random_grid,\n",
    "                            cv=2,\n",
    "                            n_iter=5,\n",
    "                            verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search for logistic regression\n",
    "rs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4128670915058853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Random Forest\n",
    "rs_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=90, max_features='sqrt',\n",
       "                      min_samples_leaf=4, min_samples_split=10,\n",
       "                      n_estimators=600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators= 600,\n",
    " min_samples_split= 10,\n",
    " min_samples_leaf= 4,\n",
    " max_features= 'sqrt',\n",
    " max_depth= 90,\n",
    " bootstrap= False)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.76122993, 1.88704604, 2.38506851, ..., 2.20968938, 2.83313827,\n",
       "        1.78865175]),\n",
       " 116985    3\n",
       " 76043     2\n",
       " 33613     2\n",
       " 75756     3\n",
       " 106084    3\n",
       "          ..\n",
       " 72863     3\n",
       " 84066     2\n",
       " 118523    2\n",
       " 116536    2\n",
       " 116537    2\n",
       " Name: Surge_Pricing_Type, Length: 26333, dtype: int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "765f0e6a717cdef1b96705705fe4f7f20bca40e4a56da864daf3394675fda3ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
